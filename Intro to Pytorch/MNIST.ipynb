{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ZfM0q4vIAlKg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdxtYE0AAr3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "407c05ee-7069-444a-f648-cb7b8ce36e16"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mtorch-0.4.1-{platform}-linux_x86_64.whl is not a valid wheel filename.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vvpPh196AtKQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wq4AlTnBA1v9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sdMlXHB0A9im",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6a9927bc-0242-4bc5-d322-3592bf488876"
      },
      "cell_type": "code",
      "source": [
        "!pip install helper\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting helper\n",
            "  Downloading https://files.pythonhosted.org/packages/be/27/80bdb3e3bd9808db34ef38b332e984ba955a09d896231ef2ca62564cb6f9/helper-2.4.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from helper) (3.13)\n",
            "Installing collected packages: helper\n",
            "Successfully installed helper-2.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PsgX74uaBP0R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import helper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OZSqVl_1BR53",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6G6Xn-KIBY-k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7bf8cae2-e3d0-4c42-bf9e-254dc2e0911c"
      },
      "cell_type": "code",
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TlsoVD9CBb99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "10774250-3bdf-4fed-fac3-398c6f698dd4"
      },
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8uenGuOIBu-w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You'll notice I created the trainloader with a batch size of 64, and shuffle=True. The batch size is the number of images we get in one iteration from the data loader and pass through our network, often called a batch. And shuffle=True tells it to shuffle the dataset every time we start going through the data loader again. But here I'm just grabbing the first batch so we can check out the data. We can see below that images is just a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images."
      ]
    },
    {
      "metadata": {
        "id": "9Da9sucSBrHh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "efe900dc-c3f8-49f6-948b-bb2d7f271d7f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFS9JREFUeJzt3X9sVfX9x/HX9V4baABLC7dbF39g\nhVhtYZBALAhSyjTsRxCVKBWYm9sgBEYhBjsCaEJioQLO6h+UKiyh2XazLhpj1FY0RsRyEaKsJUuK\nhLCGQCnQIZWitNz98c23ofa2931vb++55/J8JP3jfs7nfs7746kvzo/7ufWEQqGQAAADusXpAgDA\nDQhLADAgLAHAgLAEAAPCEgAMCEsAsAglgKSwP42Njf1uc+tPKs4pVefFnNzzk6h5DcSTiM9Zejye\nsO2hUKjfbW6VinOSUnNezMk9EjWvgeLQF+ugL730ko4ePSqPx6P169dr4sSJsQ4FAEkvprA8dOiQ\nTp06pUAgoBMnTmj9+vUKBALxrg0AkkZMD3gaGho0d+5cSVJubq4uXbqkjo6OuBYGAMkkpjPL8+fP\n6/777+95nZmZqba2No0YMSJs/8bGRuXn54fdloBbpgmXinOSUnNezMk9nJ5XzPcsbxRpEgUFBf2+\nL9VuRqfinKTUnBdzco9keMAT02W43+/X+fPne16fO3dOY8eOjWUoAHCFmMJyxowZqqurkyQdO3ZM\nfr+/30twAEgFMV2GT5kyRffff7+eeuopeTwevfDCC/GuCwCSCh9Kj7NUnJOUmvNiTu7h2nuWAHCz\nISwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwICw\nBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIA\nDAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAg\nLAHAwOd0AcCNxowZY+oXCATMY/70pz/td9uFCxd6vc7MzDSNefbsWfP+//jHP5r7RqO+vj5s+223\n3dbr9aVLl4Zk/zcbziwBwCCmM8tgMKjVq1dr/PjxkqQJEyZo48aNcS0MAJJJzJfh06ZNU2VlZTxr\nAYCkxWU4ABjEHJZff/21li9frkWLFunAgQPxrAkAko4nFAqFon1Ta2urjhw5onnz5qmlpUVLly5V\nfX290tLSwvZvampSfn7+oIsFAKfEFJY/9MQTT+iVV17R7bffHn4nHk/Y9lAo1O82t0rFOUmJm1ci\nPzqUmZmpixcv9mmzSNaPDv33v/9VRkZGr7ZU+OhQon7/BorDmC7D33nnHb355puSpLa2Nl24cEHZ\n2dmxVQcALhDT0/A5c+boueee00cffaRr167pxRdf7PcSHABSQUxhOWLECO3cuTPetQBA0orLPcuI\nO+GepesNZl533323ue8///lPU79JkybFVMuNPB7PgPeokt23337bp23EiBHq6Ojo1bZ3717zmCtX\nrjT3vX79urnvYLn2niUA3GwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMGC5\nY5yl4pykvvPKy8szv/fDDz80983JyYmqrsEYzHLHrq4uc99bbrGfk0TTN5zBLuH885//bO67du3a\nmPcTLZY7AoBLEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGLCCJ85ScU5S33m99dZb\n5vfOnz9/KEoy++qrr8K2T548WV9++WWvtpqaGtOY1n6SNGXKFHPfn/3sZ+a+4f5oW3FxsT766KNe\nbXPmzDGPefLkSXPf3Nxcc9/BYgUPALgEYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKA\nAWEJAAY+pwtAcrnvvvtM2375y18Oyf7b29tN/R555BHzmIcPHw7bHgqFolqKGKsPPvhgSPqWl5f3\naSsuLtYXX3zRqy2a5Y7oH2eWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgC\ngAHLHdHL7373O9M2r9drHrOjo8Pcd/bs2aZ+jY2N5jGBeDCdWTY3N2vu3Lk9f/7zzJkzWrJkiUpK\nSrR69Wp9//33Q1okADgtYlheuXJFmzdvVmFhYU9bZWWlSkpK9Ne//lV33nmnamtrh7RIAHBaxLBM\nS0tTdXW1/H5/T1swGFRxcbEkqaioSA0NDUNXIQAkgYj3LH0+n3y+3t06OzuVlpYmScrKylJbW9vQ\nVAcASWLQD3hCoVDEPo2NjcrPz4/5/W6TinOSpDVr1sT0vpEjR5r7/utf/4ppH7FKxWNVVlYW83vv\nvvtuc99E/7dz+ljFFJbp6em6evWqhg0bptbW1l6X6OEUFBSEbQ+FQvJ4PLGUkLTcPqcdO3aEbV+z\nZo1eeeWVntelpaXmMaN5Gj5jxgxTv3g8DXf7sQr35b9lZWXasmVLr7bnn3/ePObJkyfNfXNzc819\nBytRx2qgQI7pc5bTp09XXV2dJKm+vl4zZ86MrTIAcImIZ5ZNTU3aunWrTp8+LZ/Pp7q6Om3btk1l\nZWUKBALKycnRo48+mohaAcAxEcMyPz9fe/fu7dO+Z8+eISkIAJIRK3huApmZmea+v/nNb2LaNpC/\n/e1v5r6szEGyYm04ABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYMByx5vA\nihUrzH1vu+0207bOzk7zmLt37zb3hd2sWbOiare4ePFizO9NdZxZAoABYQkABoQlABgQlgBgQFgC\ngAFhCQAGhCUAGBCWAGBAWAKAAWEJAAYsd7wJLFq0KO5jfvXVV+a+wWAw7vtPVbNnzzb3nTZtWlTt\nFm+//XbM7011nFkCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABK3hcaty4cea+\nubm5cd//v//977iPCekPf/iDua/X642qHYPDmSUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoAB\nYQkABoQlABgQlgBgwHJHl9q0aZO5b1pamrnv9evXw7Z7vd5e2/7xj3+Yx7zZPf300+a+CxcujPv+\n//Of/5j7bt26Ne77TxWcWQKAgSksm5ubNXfuXNXU1EiSysrK9Ktf/UpLlizRkiVL9MknnwxljQDg\nuIiX4VeuXNHmzZtVWFjYq33t2rUqKioassIAIJlEPLNMS0tTdXW1/H5/IuoBgKQU8czS5/PJ5+vb\nraamRnv27FFWVpY2btyozMzMfsdobGxUfn5+2G2hUCiKct3BzXMa6LsQb9z2wQcfJKKcIefmY9Uf\nj8fT6/Wdd95pfu+1a9fiXU7cOH2sYnoaPn/+fGVkZCgvL0+7du3S66+/PuDT2YKCgrDtoVCoz4F1\nu0TNac+ePea+v/71r819B3oa3t3d3fP6F7/4hXnMuro6c99EStSxiuZp+F/+8hdz33D/sHk8nj6h\nEs3T8Hvuucfct6ury9x3sBJ1rAYK5JiehhcWFiovL0+SNGfOHDU3N8dWGQC4RExhuWrVKrW0tEiS\ngsGgxo8fH9eiACDZRLwMb2pq0tatW3X69Gn5fD7V1dVp8eLFKi0t1fDhw5Wenq7y8vJE1AoAjokY\nlvn5+dq7d2+f9kceeWRICgKAZMRyxyRzyy22OyOTJ08ekv1/8803YdtHjx7da1uyPrRJlGg+Srd9\n+3Zz32j+MuOJEyf6tN1zzz192pcsWWIeM5EPbdyG5Y4AYEBYAoABYQkABoQlABgQlgBgQFgCgAFh\nCQAGhCUAGBCWAGBAWAKAAcsdk8zIkSNN/SZOnDgk+3///ffDtpeUlPS7LZVYlzEGg8G4jylJ3377\nrbnvb3/72z5tn376aZ/2gwcPmsdE/zizBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCA\nsAQAA1bwJJlVq1Y5uv9Tp07FtC2ZZWdnm7cdOnTINObtt99u3n9LS4u578KFC819+6t1//795jFg\nx5klABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYMByR/Ty7rvvhm3/05/+\n1O+2eMrJyTH1GzdunHnMv//97/1uO3z4cK/XP/nJT0xjfvnll+b9P/PMM+a+jY2N5r5ILM4sAcCA\nsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAOWOyaZxx9/3OkS4m7ChAnmvp99\n9pmp35gxY8xjXr9+vd9tP/7xj3u93rBhg2nMyspK8/47OjrMfZG8TGFZUVGhI0eOqKurS8uWLVNB\nQYHWrVun7u5ujR07Vi+//LLS0tKGulYAcEzEsDx48KCOHz+uQCCg9vZ2LViwQIWFhSopKdG8efO0\nY8cO1dbWqqSkJBH1AoAjIt6znDp1ql599VVJ0qhRo9TZ2algMKji4mJJUlFRkRoaGoa2SgBwWMSw\n9Hq9Sk9PlyTV1tZq1qxZ6uzs7LnszsrKUltb29BWCQAO84RCoZCl4759+1RVVaXdu3fr4Ycf7jmb\nPHXqlJ5//vkBvzOwqalJ+fn58akYABxgesCzf/9+7dy5U2+88YZGjhyp9PR0Xb16VcOGDVNra6v8\nfv+A7y8oKAjbHgqF5PF4oq86iQ12TtYvlZ00aVLM+xjIgw8+GLb9wIEDmjFjRs/rzz//3Dxmsj4N\n93q96u7u7tW2adMm05jJ+jQ8Ff+fkhI3r4HOHSNehl++fFkVFRWqqqpSRkaGJGn69Omqq6uTJNXX\n12vmzJlxKhUAklPEM8v33ntP7e3tKi0t7WnbsmWLNmzYoEAgoJycHD366KNDWiQAOC1iWD755JN6\n8skn+7Tv2bNnSAoCgGTECp4kc/nyZadLMInmD4ZF89Gy0aNHx1LOgLZv3x62fd26dX22We9Fsirn\n5sPacAAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcDA/H2Wg9pJP1+tlIpf\nJzXYOf3+97839auqqop5HwNpbW0N2/6jH/1IZ8+e7XkdzVekeb1ec98ffmVaf6qrq81jrlixImw7\nv3/u4YqvaAMAEJYAYEJYAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGDAcsc4G+ycbr31\nVlO/lpYW85h+vz/Wcnp4PJ4Bl4INxLqEUZI+//xzU7+HHnooplpuxO+fe7DcEQBcgrAEAAPCEgAM\nCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwIAVPHGWqDmVlJSY+27fvt3cNzs7O2z7D1fwXLp0yTzm\nwoULzX337dtn7jtY/P65Byt4AMAlCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhL\nADBguWOcpeKcpNScF3Nyj2RY7uizDFBRUaEjR46oq6tLy5Yt08cff6xjx44pIyNDkvTss89q9uzZ\ncSkWAJJRxLA8ePCgjh8/rkAgoPb2di1YsEAPPPCA1q5dq6KiokTUCACOixiWU6dO1cSJEyVJo0aN\nUmdnZ1R/BxoAUkFU9ywDgYAOHz4sr9ertrY2Xbt2TVlZWdq4caMyMzP73wn3LF0vFefFnNwjGe5Z\nmsNy3759qqqq0u7du9XU1KSMjAzl5eVp165dOnv2rDZt2tTve5uampSfnx995QCQLEIGn376aejx\nxx8Ptbe399l2/Pjx0NNPPz3g+yWF/Rlom1t/UnFOqTov5uSen0TNayARP2d5+fJlVVRUqKqqqufp\n96pVq9TS0iJJCgaDGj9+fKRhAMDVIj7gee+999Te3q7S0tKetscee0ylpaUaPny40tPTVV5ePqRF\nAoDT+FB6nKXinKTUnBdzco9EzWugOGS5IwAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgAFhCQAG\nhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCW\nAGCQkD+FCwBux5klABgQlgBgQFgCgAFhCQAGhCUAGBCWAGDgc2KnL730ko4ePSqPx6P169dr4sSJ\nTpQRV8FgUKtXr9b48eMlSRMmTNDGjRsdrip2zc3NWrFihZ555hktXrxYZ86c0bp169Td3a2xY8fq\n5ZdfVlpamtNlRuWHcyorK9OxY8eUkZEhSXr22Wc1e/ZsZ4uMUkVFhY4cOaKuri4tW7ZMBQUFrj9O\nUt95ffzxx44fq4SH5aFDh3Tq1CkFAgGdOHFC69evVyAQSHQZQ2LatGmqrKx0uoxBu3LlijZv3qzC\nwsKetsrKSpWUlGjevHnasWOHamtrVVJS4mCV0Qk3J0lau3atioqKHKpqcA4ePKjjx48rEAiovb1d\nCxYsUGFhoauPkxR+Xg888IDjxyrhl+ENDQ2aO3euJCk3N1eXLl1SR0dHosvAANLS0lRdXS2/39/T\nFgwGVVxcLEkqKipSQ0ODU+XFJNyc3G7q1Kl69dVXJUmjRo1SZ2en64+TFH5e3d3dDlflQFieP39e\no0eP7nmdmZmptra2RJcxJL7++mstX75cixYt0oEDB5wuJ2Y+n0/Dhg3r1dbZ2dlzOZeVleW6YxZu\nTpJUU1OjpUuXas2aNbp48aIDlcXO6/UqPT1dklRbW6tZs2a5/jhJ4efl9XodP1aO3LO8Uaqstrzr\nrru0cuVKzZs3Ty0tLVq6dKnq6+tdeb8oklQ5ZvPnz1dGRoby8vK0a9cuvf7669q0aZPTZUVt3759\nqq2t1e7du/Xwww/3tLv9ON04r6amJsePVcLPLP1+v86fP9/z+ty5cxo7dmyiy4i77Oxs/fznP5fH\n49Edd9yhMWPGqLW11emy4iY9PV1Xr16VJLW2tqbE5WxhYaHy8vIkSXPmzFFzc7PDFUVv//792rlz\np6qrqzVy5MiUOU4/nFcyHKuEh+WMGTNUV1cnSTp27Jj8fr9GjBiR6DLi7p133tGbb74pSWpra9OF\nCxeUnZ3tcFXxM3369J7jVl9fr5kzZzpc0eCtWrVKLS0tkv7vnuz/f5LBLS5fvqyKigpVVVX1PCVO\nheMUbl7JcKwc+dahbdu26fDhw/J4PHrhhRd07733JrqEuOvo6NBzzz2nb775RteuXdPKlSv10EMP\nOV1WTJqamrR161adPn1aPp9P2dnZ2rZtm8rKyvTdd98pJydH5eXluvXWW50u1SzcnBYvXqxdu3Zp\n+PDhSk9PV3l5ubKyspwu1SwQCOi1117TuHHjetq2bNmiDRs2uPY4SeHn9dhjj6mmpsbRY8VXtAGA\nASt4AMCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADD4HzNR/oqw4nm1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1c542c2978>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MWLPhOiKCfQ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def activation(x):\n",
        "  return(1/1+torch.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OQO7Bu3kEAW8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Flatten the batch of images images. Then build a multi-layer network with 784 input units, 256 hidden units, and 10 output units using random tensors for the weights and biases. For now, use a sigmoid activation for the hidden layer. Leave the output layer without an activation, we'll add one that gives us a probability distribution next."
      ]
    },
    {
      "metadata": {
        "id": "Eo22dRjkD1O2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = images.view(images.shape[0], -1)\n",
        "\n",
        "# Create parameters\n",
        "w1 = torch.randn(784, 256)\n",
        "b1 = torch.randn(256)\n",
        "\n",
        "w2 = torch.randn(256, 10)\n",
        "b2 = torch.randn(10)\n",
        "\n",
        "h = activation(torch.mm(inputs, w1) + b1)\n",
        "\n",
        "out = torch.mm(h, w2) + b2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zMg3WnFvErQw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we see that the probability for each class is roughly the same. This is representing an untrained network, it hasn't seen any data yet so it just returns a uniform distribution with equal probabilities for each class.\n",
        "\n",
        "To calculate this probability distribution, we often use the softmax function. "
      ]
    },
    {
      "metadata": {
        "id": "K52PnR3AD7lU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4d17bc05-79ab-4cb1-8d3e-d1e654a23b65"
      },
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
        "\n",
        "probabilities = softmax(out)\n",
        "\n",
        "# Does it have the right shape? Should be (64, 10)\n",
        "print(probabilities.shape)\n",
        "# Does it sum to 1?\n",
        "print(probabilities.sum(dim=1))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j7Sw8DNQHVBY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Building networks with PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "UQoFjIbgHc6L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "PyTorch provides a module nn that makes building networks much simpler. Here I'll show you how to build the same one as above with 784 inputs, 256 hidden units, 10 output units and a softmax output."
      ]
    },
    {
      "metadata": {
        "id": "_naAACWmHiOK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zePp81NRHopC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "        # Define sigmoid activation and softmax output \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Pass the input tensor through each of our operations\n",
        "        x = self.hidden(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.output(x)\n",
        "        x = self.softmax(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h0PU66IGM8Tf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4b52af83-dbf7-452a-cbf7-bfd88a9adcc2"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Create the network and look at it's text representation\n",
        "model = Network()\n",
        "model"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (softmax): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "rPeZ1myvVK7w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can define the network somewhat more concisely and clearly using the torch.nn.functional module. This is the most common way you'll see networks defined as many operations are simple element-wise functions. We normally import this module as F, import torch.nn.functional as F."
      ]
    },
    {
      "metadata": {
        "id": "LQIz3E1QTNtU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Hidden layer with sigmoid activation\n",
        "        x = F.sigmoid(self.hidden(x))\n",
        "        # Output layer with softmax activation\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "        \n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "If9-yDfUV_eB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with a softmax activation as shown above. You can use a ReLU activation with the nn.ReLU module or F.relu function."
      ]
    },
    {
      "metadata": {
        "id": "fjn3zqL_TU3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a37500ea-ab50-4a7c-8dca-cdb58c5f5f5f"
      },
      "cell_type": "code",
      "source": [
        "class Netwrok(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.hidden = nn.Linear(784,128)\n",
        "    self.hidden1 = nn.Linear(128,64)\n",
        "    self.output = nn.Linear(64,10)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    \n",
        "    x= F.relu(self.hidden(x))\n",
        "    x= F.relu(self.hidden1(x))\n",
        "    x= F.softmax(self.output(x),dim=1)\n",
        "    \n",
        "    return x\n",
        "  \n",
        "  \n",
        "  \n",
        "model= Network()\n",
        "model"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "HtTufe-hWE8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "4436e907-9dcc-422f-bc8b-0894e9a70fd4"
      },
      "cell_type": "code",
      "source": [
        "print(model.hidden.weight)\n",
        "print(model.hidden.bias)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0119, -0.0108, -0.0121,  ...,  0.0009,  0.0328, -0.0144],\n",
            "        [-0.0186,  0.0295, -0.0208,  ...,  0.0056,  0.0122,  0.0105],\n",
            "        [-0.0031, -0.0218, -0.0064,  ...,  0.0284, -0.0195,  0.0020],\n",
            "        ...,\n",
            "        [-0.0062,  0.0156,  0.0110,  ...,  0.0208, -0.0183, -0.0163],\n",
            "        [-0.0029, -0.0265, -0.0174,  ...,  0.0345, -0.0151, -0.0355],\n",
            "        [-0.0165,  0.0252,  0.0006,  ...,  0.0250, -0.0231, -0.0332]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0101,  0.0203,  0.0105, -0.0251, -0.0106,  0.0257,  0.0188,  0.0200,\n",
            "         0.0129, -0.0046, -0.0058,  0.0087,  0.0143, -0.0094,  0.0275, -0.0273,\n",
            "         0.0089, -0.0182,  0.0065, -0.0307, -0.0025,  0.0115,  0.0069, -0.0341,\n",
            "         0.0002,  0.0162,  0.0139,  0.0204,  0.0179, -0.0298, -0.0084,  0.0218,\n",
            "         0.0164, -0.0040, -0.0238, -0.0107, -0.0257,  0.0200, -0.0295, -0.0060,\n",
            "        -0.0229, -0.0167,  0.0242,  0.0127, -0.0100,  0.0263,  0.0063, -0.0062,\n",
            "         0.0098, -0.0155, -0.0156,  0.0142, -0.0096, -0.0302, -0.0119, -0.0132,\n",
            "        -0.0101,  0.0023,  0.0012,  0.0259,  0.0164,  0.0340, -0.0111, -0.0208,\n",
            "         0.0320,  0.0173, -0.0016,  0.0126,  0.0110,  0.0166, -0.0122,  0.0341,\n",
            "         0.0285,  0.0303, -0.0171,  0.0255,  0.0172, -0.0251, -0.0338, -0.0089,\n",
            "        -0.0198, -0.0078, -0.0022, -0.0292, -0.0354, -0.0327, -0.0034, -0.0007,\n",
            "         0.0001, -0.0143,  0.0225, -0.0240,  0.0316,  0.0149, -0.0012,  0.0330,\n",
            "         0.0215, -0.0138,  0.0153,  0.0333, -0.0248, -0.0176,  0.0288, -0.0078,\n",
            "         0.0044, -0.0209, -0.0337,  0.0116, -0.0194,  0.0205, -0.0288, -0.0105,\n",
            "        -0.0052,  0.0312, -0.0279, -0.0284, -0.0320, -0.0114,  0.0310, -0.0025,\n",
            "         0.0020,  0.0222, -0.0329,  0.0172,  0.0210, -0.0342,  0.0277,  0.0277,\n",
            "         0.0228, -0.0155, -0.0290,  0.0147, -0.0168, -0.0072, -0.0109,  0.0349,\n",
            "        -0.0203,  0.0093, -0.0303, -0.0161,  0.0032, -0.0105,  0.0068,  0.0009,\n",
            "         0.0145,  0.0248,  0.0315, -0.0248,  0.0237, -0.0268, -0.0143,  0.0152,\n",
            "        -0.0137,  0.0193, -0.0340,  0.0207, -0.0198, -0.0211,  0.0017, -0.0240,\n",
            "        -0.0206, -0.0209, -0.0341,  0.0323, -0.0135, -0.0047, -0.0157, -0.0339,\n",
            "        -0.0253, -0.0254, -0.0210, -0.0125, -0.0147,  0.0142, -0.0033,  0.0322,\n",
            "        -0.0022,  0.0105,  0.0194,  0.0037,  0.0213,  0.0195,  0.0004, -0.0264,\n",
            "        -0.0245,  0.0081,  0.0209,  0.0202,  0.0078,  0.0249, -0.0103,  0.0324,\n",
            "         0.0056, -0.0316,  0.0339, -0.0295,  0.0291, -0.0093, -0.0001,  0.0083,\n",
            "        -0.0327, -0.0224, -0.0321, -0.0203, -0.0114,  0.0306,  0.0160,  0.0149,\n",
            "         0.0230,  0.0107, -0.0221,  0.0294,  0.0300,  0.0019, -0.0203,  0.0221,\n",
            "        -0.0327,  0.0130,  0.0164,  0.0313, -0.0174,  0.0229,  0.0204,  0.0268,\n",
            "         0.0100,  0.0258, -0.0040, -0.0219,  0.0219, -0.0109, -0.0213, -0.0291,\n",
            "         0.0076,  0.0047, -0.0350,  0.0055, -0.0114, -0.0026,  0.0257, -0.0327,\n",
            "         0.0115,  0.0195, -0.0152, -0.0087, -0.0043,  0.0198,  0.0241, -0.0332,\n",
            "         0.0230,  0.0028,  0.0234,  0.0312, -0.0027, -0.0275,  0.0152,  0.0308],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9bnJdyZ1Y4_v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Forward Pass"
      ]
    },
    {
      "metadata": {
        "id": "KH0Y7t0oXTTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "0845f651-bd6b-44d0-f55b-aae3eca35b64"
      },
      "cell_type": "code",
      "source": [
        "# Grab some data \n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
        "images.resize_(64, 1, 784)\n",
        "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
        "\n",
        "# Forward pass through the network\n",
        "img_idx = 0\n",
        "ps = model.forward(images[img_idx,:])\n",
        "\n",
        "img = images[img_idx]\n",
        "helper.view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-07a71317f718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'helper' has no attribute 'view_classify'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "N9H9BF3uZDQ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import helper \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I-d4vrkNauQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26ae31f0-a655-4c09-bb5d-135dd904d3d8"
      },
      "cell_type": "code",
      "source": [
        "helper.version"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "sdWm7eDdbo_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b16c4db4-c770-40c6-c414-3024fbaedaad"
      },
      "cell_type": "code",
      "source": [
        "!pip install helper --upgrade"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: helper in /usr/local/lib/python3.6/dist-packages (2.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from helper) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8wgtoC2abz7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "6b64b2b1-abe6-4ca4-f512-6692a4a7d17c"
      },
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.Softmax(dim=1))\n",
        "print(model)\n",
        "\n",
        "# Forward pass through the network and display output\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "ps = model.forward(images[0,:])\n",
        "helper.view_classify(images[0].view(1, 28, 28), ps)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): Softmax()\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-c280e5febbb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'helper' has no attribute 'view_classify'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ouLtkjW-cHEd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}